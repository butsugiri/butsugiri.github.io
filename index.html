<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Shun Kiyono</title>

  <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
  <link rel="stylesheet" href="/assets/css/main.css" />
</head><body a="auto">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <header>
  <h1>Shun Kiyono</h1></header><ul></ul><ul>
  <li><a href="https://scholar.google.co.jp/citations?user=LS3EdOoAAAAJ&amp;hl=ja">Google Scholar</a></li>
  <li><a href="https://github.com/butsugiri">GitHub</a></li>
</ul>

<p>メールアドレス：shun.kiyono [atat] sbintuitions.co.jp</p>

<h2 id="career">Career</h2>

<ul>
  <li>2023 Oct-Current	  SB Intuitions株式会社（SB Intuitions）</li>
  <li>2023 Oct-2024 Jun	  LINEヤフー株式会社（LY Corporation）</li>
  <li>2022 Aug-2023 Sep 	LINE株式会社（LINE Corporation）</li>
  <li>2019 Apr-2022 Jul 	国立研究開発法人理化学研究所 革新知能統合研究センター 自然言語理解チーム（RIKEN Center for Advanced Intelligence Project: Natural Language Understanding Team）</li>
</ul>

<h2 id="education">Education</h2>

<ul>
  <li>2020 Oct-2022 Mar 	東北大学大学院 情報科学研究科 システム情報科学専攻 博士後期課程 (社会人博士課程・短期修了)
    <ul>
      <li>Graduate School of Information Sciences, Tohoku University</li>
      <li>Advisor 乾 健太郎 / Kentaro Inui &amp; 鈴木 潤 / Jun Suzuki</li>
    </ul>
  </li>
  <li>2017 Apr-2019 Mar 	東北大学大学院 情報科学研究科 システム情報科学専攻 博士前期課程 修了
    <ul>
      <li>Master of Information Sciences</li>
      <li>Graduate School of Information Sciences, Tohoku University</li>
      <li>Advisor 乾 健太郎 / Kentaro Inui &amp; 鈴木 潤 / Jun Suzuki</li>
    </ul>
  </li>
  <li>2013 Apr-2017 Mar 	東北大学 工学部 情報知能システム総合学科 卒業
    <ul>
      <li>Bachelor of Engineering</li>
      <li>Department of Information and Intelligent Systems, Tohoku University</li>
      <li>Advisor 乾 健太郎 / Kentaro Inui</li>
    </ul>
  </li>
</ul>

<h2 id="publications">Publications</h2>

<h3 id="journal">Journal</h3>

<ol class="bibliography"><li><span id="gec-2020-taslp">Shun Kiyono, Jun Suzuki, Tomoya Mizumoto, and Kentaro Inui. 2020. Massive Exploration of Pseudo Data for Grammatical Error Correction. <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing</i>, 28:2134–2145.</span>
    

    
    <a href="https://ieeexplore.ieee.org/document/9134890"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li></ol>

<h3 id="international-conference">International Conference</h3>

<ol class="bibliography"><li><span id="yano2025efficient">Kazuki Yano, Sho Takase, Sosuke Kobayashi, Shun Kiyono, and Jun Suzuki. 2025. Efficient Construction of Model Family through Progressive Training Using Model Expansion. In <i>Second Conference on Language Modeling</i>.</span>
    

    
    <a href="https://openreview.net/forum?id=fuBrcTH8NM"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="takase2025spike">Sho Takase, Shun Kiyono, Sosuke Kobayashi, and Jun Suzuki. 2025. Spike No More: Stabilizing the Pre-training of Large Language Models. In <i>Second Conference on Language Modeling</i>.</span>
    

    
    <a href="https://openreview.net/forum?id=52YBEzcI0l"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="takase-etal-2025-large">Sho Takase, Ryokan Ri, Shun Kiyono, and Takuya Kato. 2025. Large Vocabulary Size Improves Large Language Models. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar, editors, <i>Findings of the Association for Computational Linguistics: ACL 2025</i>, pages 1015–1026, Vienna, Austria, July. Association for Computational Linguistics.</span>
    
    <button class="btn btnId btnPub--abstract" id="b_takase-etal-2025-large-abstract" style="outline:none;">Abstract</button>
    

    
    <a href="https://aclanthology.org/2025.findings-acl.57/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="kiyono-etal-2023-bridging">Shun Kiyono, Sho Takase, Shengzhe Li, and Toshinori Sato. 2023. Bridging the Gap between Subword and Character Segmentation in Pretrained Language Models. In Ruslan Mitkov and Galia Angelova, editors, <i>Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing</i>, pages 568–577.</span>
    

    
    <a href="https://aclanthology.org/2023.ranlp-1.62"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="takase-etal-2023-b2t">Sho Takase, Shun Kiyono, Sosuke Kobayashi, and Jun Suzuki. 2023. B2T Connection: Serving Stability and Performance in Deep Transformers. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, <i>Findings of the Association for Computational Linguistics: ACL 2023</i>, pages 3078–3095. Association for Computational Linguistics.</span>
    

    
    <a href="https://aclanthology.org/2023.findings-acl.192"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="takase-kiyono-2023-lessons">Sho Takase and Shun Kiyono. 2023. Lessons on Parameter Sharing across Layers in Transformers. In Nafise Sadat Moosavi, Iryna Gurevych, Yufang Hou, Gyuwan Kim, Young Jin Kim, Tal Schuster, and Ameeta Agrawal, editors, <i>Proceedings of The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP)</i>, pages 78–90. Association for Computational Linguistics.</span>
    

    
    <a href="https://aclanthology.org/2023.sustainlp-1.5"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="morishita-etal-2022-nt5">Makoto Morishita, Keito Kudo, Yui Oka, Katsuki Chousa, Shun Kiyono, Sho Takase, and Jun Suzuki. 2022. NT5 at WMT 2022 General Translation Task. In <i>Proceedings of the Seventh Conference on Machine Translation (WMT)</i>, pages 318–325. Association for Computational Linguistics.</span>
    

    
    <a href="https://aclanthology.org/2022.wmt-1.25"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="emnlp-2021-shape">Shun Kiyono, Sosuke Kobayashi, Jun Suzuki, and Kentaro Inui. 2021. SHAPE: Shifted Absolute Position Embedding for Transformers. In <i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</i>, pages 3309–3321. November.</span>
    

    
    <a href="https://aclanthology.org/2021.emnlp-main.266/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="emnlp-2021-konno">Ryuto Konno, Shun Kiyono, Yuichiroh Matsubayashi, Hiroki Ouchi, and Kentaro Inui. 2021. Pseudo Zero Pronoun Resolution Improves Zero Anaphora Resolution. In <i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</i>, pages 3790–3806. November.</span>
    

    
    <a href="https://aclanthology.org/2021.emnlp-main.308/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="naacl-2021-rethink-perturbation">Sho Takase and Shun Kiyono. 2021. Rethinking Perturbations in Encoder-Decoders for Fast Training. In <i>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL 2021)</i>, pages 5767–5780, Online, June. Association for Computational Linguistics.</span>
    
    <button class="btn btnId btnPub--abstract" id="b_naacl-2021-rethink-perturbation-abstract" style="outline:none;">Abstract</button>
    

    
    <a href="https://aclanthology.org/2021.naacl-main.460/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="wmt-2020-news">Shun Kiyono, Takumi Ito, Ryuto Konno, Makoto Morishita, and Jun Suzuki. 2020. Tohoku-AIP-NTT at WMT 2020 News Translation Task. In <i>Proceedings of the Fifth Conference on Machine Translation (WMT2020)</i>, pages 144–154, Online, November. Association for Computational Linguistics.</span>
    
    <button class="btn btnId btnPub--abstract" id="b_wmt-2020-news-abstract" style="outline:none;">Abstract</button>
    

    
    <a href="https://www.aclweb.org/anthology/2020.wmt-1.12"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="konno-2020-coling">Ryuto Konno, Yuichiroh Matsubayashi, Shun Kiyono, Hiroki Ouchi, Ryo Takahashi, and Kentaro Inui. 2020. An Empirical Study of Contextual Data Augmentation for Japanese Zero Anaphora Resolution. In <i>Proceedings of the 28th International Conference on Computational Linguistics (COLING2020)</i>, pages 4956–4968, Barcelona, Spain (Online), December. International Committee on Computational Linguistics.</span>
    

    
    <a href="https://www.aclweb.org/anthology/2020.coling-main.435"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="mita-2020-self">Masato Mita, Shun Kiyono, Masahiro Kaneko, Jun Suzuki, and Kentaro Inui. 2020. A Self-Refinement Strategy for Noise Reduction in Grammatical Error Correction. In <i>Findings of the Association for Computational Linguistics: EMNLP 2020</i>, pages 267–280, Online, November. Association for Computational Linguistics.</span>
    

    
    <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.26"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="acl-2020-gec">Masahiro Kaneko, Masato Mita, Shun Kiyono, Jun Suzuki, and Kentaro Inui. 2020. Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction. In <i>Proceedings of the 58th Conference of the Association for Computational Linguistics (ACL2020)</i>, pages 4248–4254. July.</span>
    

    
    <a href="https://www.aclweb.org/anthology/2020.acl-main.391/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="acl-demo-2020-espnet">Hirofumi Inaguma, Shun Kiyono, Kevin Duh, Shigeki Karita, Nelson Enrique Yalta Soplin, Tomoki Hayashi, and Shinji Watanabe. 2020. ESPnet-ST: All-in-One Speech Translation Toolkit. In <i>Proceedings of the 58th Conference of the Association for Computational Linguistics: System Demonstrations (ACL2020 Demo)</i>, pages 302–311. July.</span>
    

    
    <a href="https://www.aclweb.org/anthology/2020.acl-demos.34/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="emnlp-2019-gec">Shun Kiyono, Jun Suzuki, Masato Mita, Tomoya Mizumoto, and Kentaro Inui. 2019. An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction. In <i>2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP2019)</i>, pages 1236–1242. November.</span>
    

    
    <a href="https://www.aclweb.org/anthology/D19-1119"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="sato-etal-2019-effective">Motoki Sato, Jun Suzuki, and Shun Kiyono. 2019. Effective Adversarial Regularization for Neural Machine Translation. In <i>Proceedings of the 57th Conference of the Association for Computational Linguistics (ACL2019)</i>, pages 204–210. July.</span>
    

    
    <a href="https://www.aclweb.org/anthology/P19-1020"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="aaai-mein">Shun Kiyono, Jun Suzuki, and Kentaro Inui. 2019. Mixture of Expert/Imitator Networks: Scalable Semi-supervised Learning Framework. In <i>The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI2019)</i>, pages 4073–4081. January.</span>
    

    
    <a href="https://aaai.org/ojs/index.php/AAAI/article/view/4303"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="paclic-headline">Shun Kiyono, Sho Takase, Jun Suzuki, Naoaki Okazaki, Kentaro Inui, and Masaaki Nagata. 2018. Reducing Odd Generation from Neural Headline Generation. In <i>32nd Pacific Asia Conference on Language, Information and Computation (PACLIC 32)</i>, pages 289–303. December.</span>
    

    
    <a href="https://www.aclweb.org/anthology/Y18-1034"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="blackboxnlp-headline">Shun Kiyono, Sho Takase, Jun Suzuki, Naoaki Okazaki, Kentaro Inui, and Masaaki Nagata. 2018. Unsupervised Token-wise Alignment to Improve Interpretation of Encoder-Decoder Models. In <i>Analyzing and Interpreting Neural Networks for NLP (EMNLP2018 Workshop)</i>, pages 74–81. November.</span>
    

    
    <a href="http://aclweb.org/anthology/W18-5410"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li></ol>

<h3 id="domestic-conference">Domestic Conference</h3>

<ol class="bibliography"><li><span id="nlp2025-yano-model">矢野 一樹, 高瀬 翔, 小林 颯介, 清野 舜, and 鈴木 潤. 2025. モデル拡張を用いた段階的事前学習によるモデル系列の効率的な構築. In <i>言語処理学会第31回年次大会予稿集</i>, pages 3120–3125. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C8-4.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2024-shinzato-llm">高瀬 翔, 清野 舜, 小林 滉河, 佐藤 潤一, 加藤 卓也, 李 凌寒, 柴田 知秀, 水本 智也, and 新里 顕大. 2024. 日本語LLM構築におけるコーパスクリーニングの網羅的評価. In <i>言語処理学会第30回年次大会予稿集</i>, pages 607–612. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A3-2.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2024-takase-llm">高瀬 翔, 清野 舜, 小林 颯介, and 鈴木 潤. 2024. 大規模言語モデル事前学習の安定化. In <i>言語処理学会第30回年次大会予稿集</i>, pages 3009–3014. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A11-2.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2023-kiyono-segmentation">清野 舜, 高瀬 翔, 李 聖哲, and 佐藤 敏紀. 2023. 入力の分割単位について頑健な言語モデルの構築. In <i>言語処理学会第29回年次大会予稿集</i>, pages 789–794. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q3-3.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2022-kiyono-shape">清野 舜, 小林 颯介, 鈴木 潤, and 乾 健太郎. 2022. シフト付き絶対位置埋め込み. In <i>言語処理学会第28回年次大会予稿集</i>, pages 909–914. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/PH2-7.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2022-takase-b2t">高瀬 翔, 清野 舜, 小林 颯介, and 鈴木 潤. 2022. Transformerを多層にする際の勾配消失問題と解決法について. In <i>言語処理学会第28回年次大会予稿集</i>, pages 173–178. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/A2-5.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2021-kiyono-moe">清野 舜, 小林 颯介, 鈴木 潤, and 乾 健太郎. 2021. 単一事例エキスパートの統合によるドメイン適応. In <i>言語処理学会第27回年次大会予稿集</i>, pages 39–44. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2021/pdf_dir/B1-4.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2021-matsumoto-gec">松本 悠太, 清野 舜, and 乾 健太郎. 2021. 高再現率な文法誤り訂正システムの実現に向けて. In <i>言語処理学会第27回年次大会予稿集</i>, pages 1475–1480. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2021/pdf_dir/B1-4.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2021-takase-perturbation">高瀬 翔 and 清野 舜. 2021. エンコーダ・デコーダの学習に効果的な摂動の調査. In <i>言語処理学会第27回年次大会予稿集</i>, pages 1391–1396. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2021/pdf_dir/P7-13.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2021-konno-finetune">今野 颯人, 松林 優一郎, 清野 舜, 大内 啓樹, and 乾 健太郎. 2021. 事前学習とfinetuningの類似性に基づくゼロ照応解析. In <i>言語処理学会第27回年次大会予稿集</i>, pages 1718–1723. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2021/pdf_dir/C9-4.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2020-kiyono-gec">清野 舜, 鈴木 潤, 三田 雅人, 水本 智也, and 乾 健太郎. 2020. 大規模疑似データを用いた高性能文法誤り訂正モデルの構築. In <i>言語処理学会第26回年次大会予稿集</i>, pages 989–992. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/D4-1.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2020-konno-zar">今野 颯人, 松林 優一郎, 清野 舜, 大内 啓樹, 高橋 諒, and 乾 健太郎. 2020. マスク言語モデルを利用したデータ拡張に基づく日本語文内ゼロ照応解析. In <i>言語処理学会第26回年次大会予稿集</i>, pages 1093–1096. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/C5-1.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2020-mita-gec">三田 雅人, 清野 舜, 金子 正弘, 鈴木 潤, and 乾 健太郎. 2020. 文法誤り訂正のための自己改良戦略に基づくノイズ除去. In <i>言語処理学会第26回年次大会予稿集</i>, pages 993–996. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/D4-2.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2020-miyawaki-pas">宮脇 峻平, 清野 舜, 松林 優一郎, 今野 颯人, 高橋 諒, 大内 啓樹, and 乾 健太郎. 2020. 反復改良法を用いた日本語述語項構造解析. In <i>言語処理学会第26回年次大会予稿集</i>, pages 1097–1100. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/C5-2.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="yans2019-bert-pseudo">今野 颯人, 松林 優一郎, 清野 舜, 高橋 諒, 大内 啓樹, and 乾 健太郎. 2019. BERTによる擬似訓練データ生成に基づく述語項構造解析. In <i>第14回NLP若手の会 シンポジウム</i>. August.</span>
    

    
    
    
</li>
<li><span id="yans2019-iterative-refinement">宮脇 峻平, 加藤 拓真, 今野 颯人, 大内 啓樹, 清野 舜, 松林 優一郎, 高橋 諒, and 乾 健太郎. 2019. 日本語述語項構造のための自己回帰モデル. In <i>第14回NLP若手の会 シンポジウム</i>. August.</span>
    

    
    
    
</li>
<li><span id="nlp2019-fujii">藤井 諒, 清野 舜, 鈴木 潤, and 乾 健太郎. 2019. ニューラル機械翻訳における文脈情報の選択的利用. In <i>言語処理学会第25回年次大会予稿集</i>, pages 1459–1462. March.</span>
    

    
    <a href="http://www.anlp.jp/proceedings/annual_meeting/2019/pdf_dir/A6-3.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2019-konno">今野 颯人, 松林 優一郎, 大内 啓樹, 清野 舜, and 乾 健太郎. 2019. 前方文脈の埋め込みを利用した日本語述語項構造解析. In <i>言語処理学会第25回年次大会予稿集</i>, pages 53–56. March.</span>
    

    
    <a href="http://www.anlp.jp/proceedings/annual_meeting/2019/pdf_dir/D1-2.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2019-kitayama">北山 晃太郎, 清野 舜, 鈴木 潤, and 乾 健太郎. 2019. 画像言語同時埋め込みベクトル空間の構築に向けた埋め込み粒度の比較検討. In <i>言語処理学会第25回年次大会予稿集</i>, pages 1419–1422. March.</span>
    

    
    <a href="http://www.anlp.jp/proceedings/annual_meeting/2019/pdf_dir/P8-8.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2019-mein">清野 舜, 鈴木 潤, and 乾 健太郎. 2019. ExpertとImitatorの混合ネットワークによる大規模半教師あり学習. In <i>言語処理学会第25回年次大会予稿集</i>, pages 1006–1009. March.</span>
    

    
    <a href="http://www.anlp.jp/proceedings/annual_meeting/2019/pdf_dir/E5-1.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2018-headline">清野 舜, 高瀬 翔, 鈴木 潤, 岡崎 直観, 乾 健太郎, and 永田 昌晃. 2018. ニューラルヘッドライン生成における誤生成問題の改善. In <i>言語処理学会第24回年次大会予稿集</i>, pages 1–4. March.</span>
    

    
    <a href="http://anlp.jp/proceedings/annual_meeting/2018/pdf_dir/A1-1.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp2017-discourse">清野 舜, 田 然, 渡邉 研斗, 岡崎 直観, and 乾 健太郎. 2017. 談話関係認識のための時制情報の分析. In <i>言語処理学会第23回年次大会予稿集</i>, pages 827–830. March.</span>
    

    
    <a href="https://www.anlp.jp/proceedings/annual_meeting/2017/pdf_dir/D5-5.pdf"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="yans2016-squad">清野 舜, 岡崎 直観, and 乾 健太郎. 2016. 質問応答タスクの設定と文章読解モデルの比較・検討. In <i>第11回NLP若手の会 シンポジウム</i>. August.</span>
    

    
    
    
</li>
<li><span id="jsai2015-kaibun">清野 舜, 渡邉 研斗, 岡崎 直観, and 乾 健太郎. 2015. Bi-gram連接表と単語列変形規則に基づく回文自動生成. In <i>人工知能学会第29回全国大会</i>. May.</span>
    

    
    <a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2015/0/JSAI2015_3G3OS05a6/_article/-char/ja/"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li></ol>

<h3 id="others">Others</h3>

<ol class="bibliography"><li><span id="katouka2025datacentric">齋藤 邦章, 清野 舜, 小林 滉河, 河原塚 健人, 宮澤 一之, and 鈴木 達哉. 2025. <i>Data-centric AI入門</i>. 技術評論社, Japan, edition.</span>
    

    
    
    
</li>
<li><span id="2024-qg">井尻善久, 牛久祥孝, 片岡裕雄, 藤吉弘亘, and 延原章平. 2024. <i>コンピュータビジョン最前線 Summer 2024</i>. edition, June.</span>
    

    
    
    
</li>
<li><span id="shape-description">清野 舜. 2022. 「SHAPE: Shifted Absolute Position Embedding for Transformers」の研究を通して. <i>自然言語処理</i>, 29(1):248–252.</span>
    

    
    <a href="https://www.jstage.jst.go.jp/article/jnlp/29/1/29_248/_article/-char/ja"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="nlp-2020-100knock">岡崎 直観, 清野 舜, 高橋 諒, and 横井 祥. 2020. 言語処理100本ノック. <i>自然言語処理</i>, 27(3):2134–2145.</span>
    

    
    <a href="https://www.jstage.jst.go.jp/article/jnlp/27/3/27_703/_article/-char/ja"><button class="btn btnId btnPub--download" style="outline:none; position:relative;white-space: normal;">PDF</button></a>
    
    
    
</li>
<li><span id="arxiv-headline">Shun Kiyono, Sho Takase, Jun Suzuki, Naoaki Okazaki, Kentaro Inui, and Masaaki Nagata. 2017. Source-side Prediction for Neural Headline Generation. <i>arXiv preprint arXiv:1712.08302</i>, December.</span>
    

    
    
    
</li></ol>

<h2 id="awards">Awards</h2>

<ul>
  <li>2022 	東北大学大学院 情報科学研究科長賞</li>
  <li>2022 	言語処理学会第28回年次大会 (NLP2022) 若手奨励賞 Rate 上位12/280件</li>
  <li>2022 	言語処理学会第28回年次大会 (NLP2022) 優秀賞 Rate 上位9/386件</li>
  <li>2021 	第16回 AAMT長尾賞</li>
  <li>2020 	言語処理学会第26回年次大会 (NLP2020) 優秀賞 Rate 上位8/396件</li>
  <li>2019 	言語処理学会第25回年次大会 (NLP2019) 優秀賞 Rate 上位7/398件</li>
  <li>2018 	言語処理学会第24回年次大会 (NLP2018) 優秀賞 Rate 上位6/332件</li>
  <li>2017 	東北大学 総長賞 / Tohoku University President’s Award</li>
</ul>

<h2 id="activities">Activities</h2>

<h3 id="reviewer">Reviewer</h3>

<ul>
  <li>and more!!!</li>
  <li>自然言語処理 編集委員 (2024-)</li>
  <li>ACL 2023</li>
  <li>EMNLP 2022</li>
  <li>COLING 2022</li>
  <li>EMNLP 2021</li>
  <li>IJCAI 2021</li>
  <li>COLING 2020 (emergency reviewer)</li>
</ul>

<h3 id="invited-talk">Invited Talk</h3>

<ul>
  <li>第63回 名古屋地区NLPセミナー: より良いTransformerをつくる <a href="https://speakerdeck.com/butsugiri/yoriliang-itransformerwotukuru">slide</a></li>
  <li>第6回特許情報シンポジウム: 機械翻訳コンペティション参加報告 <a href="https://speakerdeck.com/butsugiri/ji-jie-fan-yi-konpeteisiyoncan-jia-bao-gao">slide</a></li>
</ul>

<h3 id="tutorial">Tutorial</h3>

<ul>
  <li>乾研究室内部のセミナー: 試行回数の増やし方 <a href="https://speakerdeck.com/butsugiri/increasing-number-of-attempts-ver-2021">slide</a></li>
</ul>

<h3 id="others-1">Others</h3>

<ul>
  <li>第17回最先端NLP勉強会 運営委員</li>
  <li>第16回最先端NLP勉強会 運営委員</li>
  <li>第15回最先端NLP勉強会 運営委員</li>
  <li>第10回最先端NLP勉強会 運営委員</li>
</ul>

<h3 id="blogs">Blogs</h3>

<p>I am a (co-)author of the following articles:</p>

<ul>
  <li><a href="https://www.sbintuitions.co.jp/blog/entry/2025/03/07/093143">Sarashina2.2-Instruct：コンパクトかつ性能の高い日本語Instructモデル - SB Intuitions TECH BLOG</a></li>
  <li><a href="https://www.sbintuitions.co.jp/blog/entry/2024/06/26/115641">大規模な日本語の事前学習言語モデルSarashina1・2の公開 - SB Intuitions TECH BLOG</a></li>
  <li><a href="https://engineering.linecorp.com/ja/blog/3.6-billion-parameter-japanese-language-model">36億パラメータの日本語言語モデルを公開しました</a></li>
</ul>

      </div>
    </main>
  </body>
</html>